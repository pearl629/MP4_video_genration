# -*- coding: utf-8 -*-
"""MP4 Video (AI Automatic).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VQZGsciEg64SoG_JO1zNuMKTPUH5HFtb

Installs system dependencies
"""

!apt-get update -qq
!apt-get install -y libcairo2-dev ffmpeg texlive texlive-latex-extra texlive-fonts-extra texlive-latex-recommended texlive-science tipa libpango1.0-dev
!pip install manim gtts pydub moviepy pillow anthropic

!pip install  groq
!pip install pyttsx3
!pip install --upgrade numpy scipy manim

!pip install gTTS
!sudo apt update
!sudo apt install -y libcairo2-dev pkg-config python3-dev ffmpeg libpango1.0-dev
!pip install manim
!sudo apt update
!sudo apt install espeak -y

"""import libreries"""

from groq import Groq
import json
import re
import os
from gtts import gTTS
import subprocess
from manim import *

client = Groq(api_key="enter api")

"""PART A ‚Äî Manual Research Task

1. Analyze the reference video (Manual)
"""

style_profile= {
  "style_profile_id": "websocket_2d_explainer_v1",
  "visual_styles": {
    "2d_explainer": True,
    "line_based_animation": True,
    "flowchart_arrows":True,
    "character_based": False,
    "whiteboard_doodle": False,
    "ui_walkthrough": True,
    "kinetic_typography": False,
    "infographic_motion": True,
    "storytelling_scenes": False
  },
  "core_visuals": {
    "vector_layouts":True,
    "packet_flow_animation": True,
    "dynamic_data_tables": True,
    "protocol_state_morphing": True
  }
}

"""PART B ‚Äî Automatic System

2. Topic ‚Üí Script (AI Automatic)
"""

def organizer(context):
    chat_completion = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {
                "role": "system",
                "content": (
                    "You are an expert educational content planner.\n"
                    "Given a topic, identify ALL necessary subtopics needed "
                    "to clearly explain it in approximately 10 minutes.\n\n"
                    "Rules:\n"
                    "- Assume 10 minutes ‚âà 1400 words total.\n"
                    "- Allocate more words to complex or core concepts.\n"
                    "- Allocate fewer words to introductions or summaries.\n"
                    "- Ensure the sum of allocated_words ‚âà 1400.\n"
                    "- Preserve logical teaching order.\n\n"
                    "Return STRICTLY valid JSON in this format:\n"
                    "{\n"
                    "  \"total_duration_minutes\": 10,\n"
                    "  \"total_words\": 1400,\n"
                    "  \"topics\": [\n"
                    "    {\n"
                    "      \"title\": string,\n"
                    "      \"importance\": \"low|medium|high|very_high\",\n"
                    "      \"allocated_words\": number,\n"
                    "      \"subtopics\": [same structure]\n"
                    "    }\n"
                    "  ]\n"
                    "}\n\n"
                    "Return ONLY JSON. No markdown. No explanations."
                )
            },
            {"role": "user", "content": context}
        ],
        temperature=0.6,
        max_tokens=1800,
        top_p=1,
        stream=True
    )

    response_content = ""
    for chunk in chat_completion:
        chunk_content = getattr(chunk.choices[0].delta, "content", "")
        if chunk_content:
            response_content += chunk_content

    clean_text = re.sub(r"<think>.*?</think>", "", response_content, flags=re.DOTALL).strip()

    try:
        planned_structure = json.loads(clean_text)
    except json.JSONDecodeError as e:
        raise ValueError("Invalid JSON returned by LLM") from e

    return planned_structure

def clean_narration(text):

    text = re.sub(r"\[.*?\]", "", text)

    text = re.sub(r"\(.*?\)", "", text)

    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)

    text = re.sub(r"\s+", " ", text).strip()

    return text
def flatten_topics(topics):
    ordered = []

    for topic in topics:
        ordered.append(topic)
        for subtopic in topic.get("subtopics", []):
            ordered.append(subtopic)

    return ordered

def generate_topic_content(topic_node, memory):

    title = topic_node["title"]
    word_limit = topic_node["allocated_words"]

    is_first_topic = len(memory["covered_topics"]) == 0

    # ---- System prompt for narration ----
    narration_system_prompt = (
        "You are an educational explanation agent.\n"
        "This is a SINGLE continuous YouTube-style educational video.\n\n"
        "Rules:\n"
        "- Output ONLY spoken narration.\n"
        "- Do NOT include stage directions, music, or visual cues.\n"
        "- Do NOT use brackets [] or parentheses ().\n"
        "- Use the provided word limit STRICTLY.\n"
        "- Spoken, smooth, educational tone.\n"
    )

    if is_first_topic:
        narration_system_prompt += (
            "- This is the FIRST topic of the video.\n"
            "- Start naturally without assuming prior content.\n"
        )
    else:
        narration_system_prompt += (
            "- Continue naturally from previous explanation.\n"
            "- Do NOT repeat or redefine earlier topics.\n"
        )

    narration_system_prompt += f"\nPreviously covered topics: {memory['covered_topics']}\n"

    # ---- Generate narration ----
    chat_completion = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": narration_system_prompt},
            {
                "role": "user",
                "content": (
                    f"Current topic: {title}\n"
                    f"Word limit: {word_limit}\n\n"
                    "Generate the explanation."
                )
            }
        ],
        temperature=0.6,
        max_tokens=word_limit * 2,
        top_p=1,
        stream=True
    )

    narration = ""
    for chunk in chat_completion:
        chunk_content = getattr(chunk.choices[0].delta, "content", "")
        if chunk_content:
            narration += chunk_content

    # Clean narration
    narration = re.sub(r"\[.*?\]|\(.*?\)|<think>.*?</think>", "", narration, flags=re.DOTALL).strip()

    # ---- Update memory ----
    memory["covered_topics"].append(title)
    memory["covered_explanations"].append(narration)

    # ---- System prompt for scene generation ----
    scene_system_prompt = (
        "You are a video scene planning agent.\n\n"
    "Given a spoken narration for ONE topic, break it into:\n"
    "- Scene-by-scene concepts\n"
    "- Short explanation per scene (for visuals)\n\n"
    "Rules:\n"
    "- Each scene must represent a distinct visual change or idea.\n"
    "- Use diagram-style, conceptual, or infographic visuals.\n"
    "- Do NOT write narration.\n"
    "- Do NOT include camera, music, cinematic cues, or repeated explanations.\n"
    "- Avoid redundancy with previous topics (if provided).\n"
    "- Keep explanations short, precise, and easy to visualize.\n"
    "- Include up to 1‚Äì2 sentences per short_explanation.\n"
    "- Number scenes sequentially.\n"
    "- ONLY return valid JSON with NO extra text.\n"
    "Format:\n"
    "{\n"
    "  \"topic\": string,          # Topic title\n"
    "  \"scenes\": [\n"
    "    {\n"
    "      \"scene\": number,      # Scene number\n"
    "      \"concept\": string,    # Visual concept name, short and descriptive\n"
    "      \"short_explanation\": string   # Visual description for AI / animators\n"
    "    }\n"
    "  ]\n"
    "}\n"
    "Notes:\n"
    "- Make each concept unique and directly tied to a visual element.\n"
    "- Minimize repetition of phrases across scenes.\n"
    "- Think in terms of what the viewer should see, not hear."
    )

    # ---- Generate scene-by-scene JSON ----
    chat_completion_scene = client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": scene_system_prompt},
            {
                "role": "user",
                "content": (
                    f"Topic: {title}\n\n"
                    f"Narration:\n{narration}"
                )
            }
        ],
        temperature=0.4,
        max_tokens=800,
        top_p=1
    )

    scene_output = chat_completion_scene.choices[0].message.content

    # ---- Safe JSON parsing ----
    def safe_json_loads(text):
        match = re.search(r"{.*}", text, flags=re.DOTALL)
        if not match:
            print("Warning: No JSON found in scene output. Returning empty scenes.")
            return {"topic": title, "scenes": []}
        return json.loads(match.group(0))

    scene_json = safe_json_loads(scene_output)

    # ---- Return both narration and scene-by-scene together ----
    return {
        "title": title,
        "allocated_words": word_limit,
        "narration_script": clean_narration(narration),
        "scene_by_scene": scene_json.get("scenes", [])
    }

planned_structure=organizer("websocket")

final_script = []
memory = {"covered_topics": [], "covered_explanations": []}

for topic_node in flatten_topics(planned_structure["topics"]):
    content = generate_topic_content(topic_node, memory)
    final_script.append(content)

"""3. Script ‚Üí Animation Blueprint"""

def generate_video_blueprint(final_script, style_profile, ai_client=client):


    blueprints = []

    for topic_node in final_script:
        topic_title = topic_node["title"]
        narration_script = topic_node["narration_script"]
        scene_list = topic_node.get("scene_by_scene", [])

        # ---------- TIMING LOGIC (IMPORTANT) ----------
        words = len(narration_script.split())
        total_duration = max(6, int(words / 2.5))   # ~2.5 words/sec
        per_scene_time = max(4, int(total_duration / max(1, len(scene_list))))

        # ---------- TRY AI (OPTIONAL) ----------
        blueprint = None
        if ai_client is not None:
            try:
                ai_prompt = f"""
You are an expert animation blueprint generator.

INPUTS:
Title: {topic_title}
Narration: {narration_script}
Scenes: {json.dumps(scene_list)}
Style Profile: {json.dumps(style_profile)}

TASK:
Generate a STRICT JSON blueprint.

RULES:
- Use diagrammatic / conceptual visuals
- One storyboard entry per scene
- Timing must be realistic
- Do NOT repeat narration
- Return ONLY valid JSON

FORMAT:
{{
  "topic": "{topic_title}",
  "narration_script": "...",
  "storyboard": [
    {{
      "scene": 1,
      "concept": "...",
      "short_explanation": "...",
      "visual_elements": ["..."],
      "animation_instructions": "...",
      "timing": number,
      "transition": "...",
      "asset_prompt": "..."
    }}
  ]
}}
"""
                response = ai_client.chat.completions.create(
                    model="llama-3.1-8b-instant",
                    messages=[{"role": "user", "content": ai_prompt}],
                    temperature=0.5,
                    max_tokens=2000
                )

                raw = response.choices[0].message.content
                match = re.search(r"{.*}", raw, flags=re.DOTALL)
                if match:
                    blueprint = json.loads(match.group(0))
            except Exception:
                blueprint = None

        # ---------- SAFE FALLBACK (NEVER FAILS) ----------
        if blueprint is None:
            storyboard = []
            for idx, scene in enumerate(scene_list, start=1):
                concept = scene.get("concept", f"Scene {idx}")

                storyboard.append({
                    "scene": idx,
                    "concept": concept,
                    "short_explanation": scene.get("short_explanation", ""),
                    "visual_elements": [
                        "diagram node",
                        "directional arrow",
                        "label text"
                    ],
                    "animation_instructions": (
                        "stepwise reveal of elements, subtle motion, "
                        "highlight key relationships"
                    ),
                    "timing": per_scene_time,
                    "transition": "fade",
                    "asset_prompt": (
                        f"{concept}, clean vector diagram, "
                        f"{style_profile.get('art_style', 'modern flat style')}, "
                        "educational, minimal, white background"
                    )
                })

            blueprint = {
                "topic": topic_title,
                "narration_script": narration_script,
                "storyboard": storyboard
            }

        blueprints.append(blueprint)

    return blueprints

blueprint=generate_video_blueprint(final_script,  style_profile)

"""4. Blueprint ‚Üí MP4 Video"""

import os
import re
import subprocess
from gtts import gTTS
import json

try:
    from manim import *
    print("Manim imported successfully!")
except ImportError as e:
    print(f"Manim import failed: {e}")
    raise

# --- Folders ---
os.makedirs("narrations2", exist_ok=True)
os.makedirs("scenes", exist_ok=True)
os.makedirs("final_videos", exist_ok=True)

# --- Step 1: Generate narration MP3s ---
print("=" * 50)
print("STEP 1: Generating narrations...")
print("=" * 50)

narration_files = []
for i, topic in enumerate(blueprint):
    script_text = topic.get('narration_script') or topic.get('narration', '')

    if not script_text:
        print(f"‚ö†Ô∏è No narration found for topic {i+1}, skipping...")
        narration_files.append(None)
        continue

    title_clean = re.sub(r'\W+', '_', topic['topic'])
    tts = gTTS(text=script_text, lang='en')
    audio_path = f"narrations2/{i+1}_{title_clean}.mp3"
    tts.save(audio_path)
    narration_files.append(audio_path)
    print(f"‚úì {i+1}/{len(blueprint)}: {title_clean[:40]}")

# --- Step 2: Blueprint-Driven Scene Renderer ---
print("\n" + "=" * 50)
print("STEP 2: Generating scene videos from blueprint...")
print(f"Total topics: {len(blueprint)}")
print("=" * 50)

scene_files = []
scene_counter = 0

def create_element_from_description(description):
    """Create Manim object from visual element description"""
    if isinstance(description, dict):
        elem_type = description.get('type', '').lower()
        label = description.get('label', '')
        direction = description.get('direction', '')

        if elem_type == 'arrow':
            if direction == 'both':
                return DoubleArrow(LEFT * 2, RIGHT * 2, color=GREEN, buff=0)
            elif direction == 'left':
                return Arrow(LEFT * 2, RIGHT * 2, color=GREEN, buff=0)
            elif direction == 'right':
                return Arrow(RIGHT * 2, LEFT * 2, color=GREEN, buff=0)
            else:
                return DoubleArrow(LEFT * 2, RIGHT * 2, color=GREEN, buff=0)

        elif elem_type == 'client':
            rect = RoundedRectangle(width=1.5, height=1.2, corner_radius=0.1, color=BLUE, fill_opacity=0.2)
            text = Text(label or "Client", font_size=18)
            return VGroup(rect, text)

        elif elem_type == 'server':
            server = VGroup()
            for i in range(3):
                layer = Rectangle(width=1.5, height=0.3, color=PURPLE, fill_opacity=0.3)
                layer.shift(UP * (0.4 - i * 0.4))
                server.add(layer)
            text = Text(label or "Server", font_size=18).next_to(server, DOWN, buff=0.2)
            return VGroup(server, text)

        elif elem_type == 'line':
            thickness = description.get('thickness', 3)
            return Line(LEFT * 2, RIGHT * 2, color=GREEN, stroke_width=thickness)

        elif elem_type in ['clock', 'live_chat', 'connection']:
            return Text(label or elem_type.title(), font_size=24, color=BLUE)

    # String descriptions
    desc_lower = str(description).lower()

    if 'browser' in desc_lower or 'web_browser' in desc_lower:
        rect = RoundedRectangle(width=1.5, height=1.2, corner_radius=0.1, color=BLUE, fill_opacity=0.2)
        bar = Rectangle(width=1.5, height=0.2, color=BLUE_D, fill_opacity=1).move_to(rect.get_top() - UP * 0.1)
        text = Text("Browser", font_size=16).next_to(rect, DOWN, buff=0.2)
        return VGroup(rect, bar, text)

    elif 'server' in desc_lower:
        server = VGroup()
        for i in range(3):
            layer = Rectangle(width=1.5, height=0.3, color=PURPLE, fill_opacity=0.3)
            layer.shift(UP * (0.4 - i * 0.4))
            server.add(layer)
        text = Text("Server", font_size=16).next_to(server, DOWN, buff=0.2)
        return VGroup(server, text)

    elif 'globe' in desc_lower:
        circle = Circle(radius=1, color=BLUE, fill_opacity=0.1)
        lines = VGroup()
        for i in range(-2, 3):
            ellipse = Ellipse(width=2, height=0.3, color=BLUE_D)
            ellipse.shift(UP * i * 0.4)
            lines.add(ellipse)
        vert_ellipse = Ellipse(width=0.4, height=2, color=BLUE_D)
        lines.add(vert_ellipse)
        return VGroup(circle, lines)

    elif 'lightning' in desc_lower or 'bolt' in desc_lower:
        points = [[0.2, 1, 0], [0, 0.2, 0], [0.3, 0.2, 0], [-0.2, -1, 0], [0, -0.2, 0], [-0.3, -0.2, 0], [0.2, 1, 0]]
        return Polygon(*points, color=YELLOW, fill_opacity=1, stroke_width=2)

    elif 'arrow' in desc_lower:
        return Arrow(LEFT * 2, RIGHT * 2, color=GREEN, buff=0)

    elif 'line' in desc_lower or 'connection' in desc_lower or 'continuous' in desc_lower:
        return Line(LEFT * 2, RIGHT * 2, color=GREEN, stroke_width=4)

    elif 'chat' in desc_lower:
        bubble = RoundedRectangle(width=2, height=1.2, corner_radius=0.2, color=GREEN, fill_opacity=0.2)
        lines = VGroup()
        for i in range(3):
            line = Line(LEFT * 0.7, RIGHT * 0.7, color=WHITE)
            line.shift(UP * (0.4 - i * 0.4))
            lines.add(line)
        lines.move_to(bubble)
        return VGroup(bubble, lines)

    elif 'gaming' in desc_lower or 'game' in desc_lower:
        screen = Rectangle(width=2.5, height=1.8, color=PURPLE, fill_opacity=0.2)
        buttons = VGroup()
        for i in range(2):
            for j in range(2):
                btn = Circle(radius=0.12, color=RED, fill_opacity=1)
                btn.shift(RIGHT * (i - 0.5) * 0.35 + UP * (j - 0.5) * 0.35 + DOWN * 0.4)
                buttons.add(btn)
        return VGroup(screen, buttons)

    elif 'dot' in desc_lower or 'disconnected' in desc_lower:
        dots = VGroup()
        for i in range(5):
            dot = Dot(color=RED)
            dot.shift(RIGHT * (i - 2) * 0.6)
            dots.add(dot)
        return dots

    elif 'x' in desc_lower or 'red_x' in desc_lower:
        x = VGroup(
            Line(UL * 0.8, DR * 0.8, color=RED, stroke_width=8),
            Line(UR * 0.8, DL * 0.8, color=RED, stroke_width=8)
        )
        return x

    elif 'socket' in desc_lower:
        body = Rectangle(width=0.5, height=0.8, color=YELLOW, fill_opacity=0.5)
        prongs = VGroup()
        for i in range(2):
            prong = Rectangle(width=0.1, height=0.3, color=YELLOW, fill_opacity=1)
            prong.shift(UP * 0.65 + RIGHT * (i - 0.5) * 0.15)
            prongs.add(prong)
        return VGroup(body, prongs)

    elif 'packet' in desc_lower or 'message' in desc_lower:
        rect = Rectangle(width=1, height=0.6, color=ORANGE, fill_opacity=0.5)
        text = Text("DATA", font_size=12).move_to(rect)
        return VGroup(rect, text)

    elif 'handshake' in desc_lower:
        hand1 = Rectangle(width=0.4, height=0.8, color=BLUE, fill_opacity=0.5).shift(LEFT * 0.4)
        hand2 = Rectangle(width=0.4, height=0.8, color=GREEN, fill_opacity=0.5).shift(RIGHT * 0.4)
        conn = Line(hand1.get_right(), hand2.get_left(), color=YELLOW)
        return VGroup(hand1, hand2, conn)

    elif 'header' in desc_lower:
        envelope = Rectangle(width=1.5, height=1, color=BLUE, fill_opacity=0.2)
        flap = Polygon([-0.75, 0.5, 0], [0, 0.2, 0], [0.75, 0.5, 0], color=BLUE_D, fill_opacity=0.5)
        return VGroup(envelope, flap)

    elif 'upgrade' in desc_lower:
        base = Rectangle(width=1, height=0.3, color=GREEN, fill_opacity=0.5)
        arrow = Polygon([0, 0.8, 0], [-0.4, 0.3, 0], [0.4, 0.3, 0], color=GREEN, fill_opacity=1)
        return VGroup(base, arrow)

    elif 'live' in desc_lower or 'update' in desc_lower:
        screen = Rectangle(width=2, height=1.5, color=GREEN, fill_opacity=0.1)
        pulse = Circle(radius=0.3, color=RED, fill_opacity=0.5)
        return VGroup(screen, pulse)

    elif 'split' in desc_lower:
        left = Rectangle(width=1.8, height=2.5, color=BLUE, fill_opacity=0.1).shift(LEFT * 1.5)
        right = Rectangle(width=1.8, height=2.5, color=PURPLE, fill_opacity=0.1).shift(RIGHT * 1.5)
        divider = Line(UP * 1.5, DOWN * 1.5, color=WHITE)
        return VGroup(left, right, divider)

    elif 'building' in desc_lower or 'foundation' in desc_lower:
        foundation = Rectangle(width=2.5, height=0.5, color=GRAY, fill_opacity=0.7).shift(DOWN * 1)
        blocks = VGroup()
        for i in range(3):
            block = Square(side_length=0.7, color=BLUE, fill_opacity=0.3)
            block.shift(UP * (i * 0.8 - 0.5))
            blocks.add(block)
        return VGroup(foundation, blocks)

    else:
        # Default fallback
        return Text(str(description)[:15], font_size=20, color=BLUE)

def render_blueprint_scene(scene_info, scene_counter):
    """Render scene using blueprint's visual_elements and animation_instructions"""

    concept = scene_info.get('concept', f"Scene {scene_counter}")
    visual_elements = scene_info.get('visual_elements', [])
    animation_instructions = scene_info.get('animation_instructions', '').lower()
    duration = scene_info.get('timing') or scene_info.get('duration_seconds', 5)
    explanation = scene_info.get('short_explanation', '')

    class BlueprintScene(Scene):
        def construct(self):
            # Title
            title = Text(concept[:55], font_size=20, color=WHITE).to_edge(UP)
            self.play(Write(title), run_time=0.5)

            # Create visual elements from blueprint
            elements = []
            num_elements = len(visual_elements)

            if num_elements == 0:
                # Fallback
                elem = Text(concept[:20], font_size=24)
                elements.append(elem)
            else:
                # Calculate positions
                if num_elements == 1:
                    positions = [ORIGIN]
                elif num_elements == 2:
                    positions = [LEFT * 2.5, RIGHT * 2.5]
                elif num_elements == 3:
                    positions = [LEFT * 3, ORIGIN, RIGHT * 3]
                else:
                    # Grid for many elements
                    cols = min(3, num_elements)
                    positions = []
                    for i in range(num_elements):
                        row = i // cols
                        col = i % cols
                        x = (col - (cols-1)/2) * 2.5
                        y = 0.5 - row * 1.8
                        positions.append(np.array([x, y, 0]))

                # Create each element
                for i, elem_desc in enumerate(visual_elements):
                    elem = create_element_from_description(elem_desc)
                    if i < len(positions):
                        elem.move_to(positions[i])
                    elements.append(elem)

                    # Animate appearance
                    if 'arrow' in str(elem_desc).lower():
                        self.play(GrowArrow(elem) if hasattr(elem, 'get_start') else Create(elem), run_time=0.5)
                    elif 'line' in str(elem_desc).lower():
                        self.play(Create(elem), run_time=0.6)
                    else:
                        self.play(FadeIn(elem), run_time=0.4)

            # Apply animations based on instructions
            anim_time = duration - 2  # Reserve time for title/explanation

            if 'spin' in animation_instructions or 'rotating' in animation_instructions:
                # Spin animation
                for elem in elements:
                    self.play(Rotate(elem, angle=TAU), run_time=anim_time)

            elif 'flash' in animation_instructions or 'flashing' in animation_instructions:
                # Flashing animation
                cycles = int(anim_time / 0.8)
                for _ in range(cycles):
                    for elem in elements:
                        self.play(elem.animate.set_fill(YELLOW, opacity=1), run_time=0.2)
                        self.play(elem.animate.set_fill(WHITE, opacity=0.5), run_time=0.2)
                        self.wait(0.4)

            elif 'flowing' in animation_instructions or 'flow' in animation_instructions:
                # Data flow animation
                if len(elements) >= 2:
                    for _ in range(int(anim_time / 1.5)):
                        dot = Dot(color=YELLOW, radius=0.1).move_to(elements[0].get_center())
                        self.play(dot.animate.move_to(elements[-1].get_center()), run_time=1.5, rate_func=linear)
                        self.remove(dot)
                else:
                    self.wait(anim_time)

            elif 'both ways' in animation_instructions or 'bidirectional' in animation_instructions:
                # Bidirectional flow
                if len(elements) >= 2:
                    for _ in range(int(anim_time / 2)):
                        dot1 = Dot(color=GREEN, radius=0.08).move_to(elements[0].get_center())
                        dot2 = Dot(color=ORANGE, radius=0.08).move_to(elements[-1].get_center())
                        self.play(
                            dot1.animate.move_to(elements[-1].get_center()),
                            dot2.animate.move_to(elements[0].get_center()),
                            run_time=1,
                            rate_func=linear
                        )
                        self.remove(dot1, dot2)
                        self.wait(0.5)
                else:
                    self.wait(anim_time)

            elif 'split-screen' in animation_instructions or 'live update' in animation_instructions:
                # Alternating highlights
                if len(elements) >= 2:
                    for _ in range(int(anim_time / 1.5)):
                        self.play(elements[0].animate.scale(1.1), run_time=0.4)
                        self.play(elements[0].animate.scale(1/1.1), run_time=0.3)
                        self.play(elements[1].animate.scale(1.1), run_time=0.4)
                        self.play(elements[1].animate.scale(1/1.1), run_time=0.3)
                else:
                    self.wait(anim_time)

            elif 'marked' in animation_instructions or 'cross' in animation_instructions:
                # Draw X
                for elem in elements:
                    bounds = elem.get_corner(UL), elem.get_corner(DR)
                    x1 = Line(bounds[0], bounds[1], color=RED, stroke_width=6)
                    x2 = Line([bounds[0][0], bounds[1][1], 0], [bounds[1][0], bounds[0][1], 0], color=RED, stroke_width=6)
                    self.play(Create(x1), Create(x2), run_time=0.8)
                self.wait(anim_time - 0.8)

            elif 'comparison' in animation_instructions:
                # Highlight comparison
                for _ in range(int(anim_time / 2)):
                    for elem in elements:
                        self.play(elem.animate.set_stroke(YELLOW, width=4), run_time=0.5)
                        self.wait(0.2)
                        self.play(elem.animate.set_stroke(WHITE, width=1), run_time=0.5)

            elif 'emphasize' in animation_instructions or 'zoom' in animation_instructions:
                # Scale emphasis
                cycles = int(anim_time / 1.5)
                for _ in range(cycles):
                    for elem in elements:
                        self.play(elem.animate.scale(1.2), run_time=0.75)
                        self.play(elem.animate.scale(1/1.2), run_time=0.75)

            else:
                # Default: subtle motion
                cycles = int(anim_time / 2)
                for _ in range(cycles):
                    for elem in elements:
                        self.play(elem.animate.shift(UP * 0.1), rate_func=there_and_back, run_time=2)

            # Add explanation at bottom
            if explanation:
                words = explanation.split()
                lines = []
                current_line = []
                for word in words:
                    current_line.append(word)
                    if len(' '.join(current_line)) > 60:
                        lines.append(' '.join(current_line))
                        current_line = []
                if current_line:
                    lines.append(' '.join(current_line))

                expl_text = Text('\n'.join(lines[:3]), font_size=16, color=GRAY).to_edge(DOWN, buff=0.3)
                self.play(FadeIn(expl_text), run_time=0.5)
                self.wait(0.5)

    # Render
    output_filename = f"scene_{scene_counter:04d}"
    final_output = f"scenes/{output_filename}.mp4"

    config.output_file = output_filename
    config.media_dir = "scenes"
    config.pixel_width = 1920
    config.pixel_height = 1080
    config.frame_rate = 30

    scene = BlueprintScene()
    scene.render()

    # Find rendered file
    for resolution in ['1080p30', '720p30', '480p15']:
        manim_output = f"scenes/videos/{resolution}/{output_filename}.mp4"
        if os.path.exists(manim_output):
            subprocess.run(['cp', manim_output, final_output], check=True)
            return final_output

    raise FileNotFoundError("Video not rendered")

# Render all scenes
for topic_idx, topic in enumerate(blueprint):
    print(f"\n[{topic_idx + 1}/{len(blueprint)}] {topic['topic'][:50]}")

    scenes = topic.get('storyboard', [])

    for scene in scenes:
        scene_counter += 1
        print(f"  [{scene_counter}] {scene.get('concept', 'Scene')[:40]}...", end=" ")

        try:
            scene_file = render_blueprint_scene(scene, scene_counter)
            scene_files.append(scene_file)
            print("‚úì")
        except Exception as e:
            print(f"‚úó {str(e)[:50]}")
            import traceback
            traceback.print_exc()

print(f"\n‚úì Total: {len(scene_files)} scenes rendered")

# --- Step 3: Merge with audio ---
print("\n" + "=" * 50)
print("STEP 3: Creating final videos with audio...")
print("=" * 50)

final_video_parts = []
scene_idx = 0

for topic_idx, topic in enumerate(blueprint):
    title_clean = re.sub(r'\W+', '_', topic['topic'])
    scenes = topic.get('storyboard', [])
    num_scenes = len(scenes)

    topic_scene_files = scene_files[scene_idx:scene_idx + num_scenes]
    scene_idx += num_scenes

    # Concatenate scene videos
    if len(topic_scene_files) > 1:
        concat_file = f"scenes/concat_{topic_idx+1}.txt"
        with open(concat_file, 'w') as f:
            for sf in topic_scene_files:
                f.write(f"file '{os.path.abspath(sf)}'\n")

        video_file = f"scenes/topic_{topic_idx+1}.mp4"
        subprocess.run([
            'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
            '-i', concat_file, '-c', 'copy', video_file
        ], capture_output=True, text=True, check=True)
    else:
        video_file = topic_scene_files[0] if topic_scene_files else None

    # Add narration audio
    if video_file and narration_files[topic_idx]:
        output_file = f"final_videos/{topic_idx+1:02d}_{title_clean}.mp4"
        subprocess.run([
            'ffmpeg', '-y', '-i', video_file, '-i', narration_files[topic_idx],
            '-c:v', 'copy', '-c:a', 'aac', '-shortest', output_file
        ], capture_output=True, text=True, check=True)

        print(f"[{topic_idx+1}] ‚úì {title_clean[:40]}")
        final_video_parts.append(output_file)

# Final merge
if final_video_parts:
    concat_file = "final_videos/final.txt"
    with open(concat_file, 'w') as f:
        for part in final_video_parts:
            f.write(f"file '{os.path.abspath(part)}'\n")

    final_output = "final_videos/Complete_Video.mp4"
    subprocess.run([
        'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
        '-i', concat_file, '-c', 'copy', final_output
    ], capture_output=True, text=True, check=True)

    print(f"\n{'='*50}")
    print(f"‚úÖ COMPLETE!")
    print(f"üìπ {final_output}")
    print(f"üìä {len(final_video_parts)} topics, {len(scene_files)} scenes")
    print(f"{'='*50}")